# Mushroom edibility classifier with XGBoost

# Part 1 - Data Preprocessing

# Importing the libraries
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('mushrooms.csv', na_values = "?") #Import data, treat ? as NaN
dataset.dtypes #Inspect data types
dataset.head()

# Limpeza das vari√°veis
dataset["stalk-root"].value_counts() # inspect column with NaN values
dataset = dataset.fillna({"stalk-root": "b"}) # substitute NaN with most occurent value
cleanup_nums = {"ring-number": {"n": 0, "one": 1, "two" : 2}}
dataset.replace(cleanup_nums, inplace = True)

# Encoding categorical variables
print('Original features:\n', list(dataset.columns), '\n')
dataset_dummies = pd.get_dummies(dataset)
print('Features after encoding:\n', list(dataset_dummies.columns))

# Part 2 - Creating the features (X) and label (y) matrices, splitting training and test datasets

# X and Y matrices
features = dataset_dummies.loc[:, 'cap-shape_b':'habitat_w']
X = features.values
y = dataset_dummies['class_p'].values # y (is poisonous?) = 1/0 (yes/no)

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# Part 3 - Fitting the regressor and processing results

# Fitting XGBoost to the Training Set
from xgboost import XGBClassifier
classifier = XGBClassifier()
classifier.fit(X_train, y_train)

# Predicting the test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

# Part 4 - Hyper parameter optimization

# Applying k-Fold Cross Validation
from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y= y_train, cv = 10)
accuracies.mean()
accuracies.std()

# Applying Grid Search to find the best model and the best parameters
from sklearn.model_selection import GridSearchCV
parameters = [{'max_depth': [2, 3, 4],
               'reg_lambda': [0, 0.1, 0.2],
               'gamma': [0, 0.001, 0.01]}]
grid_search = GridSearchCV(estimator = classifier,
                           param_grid = parameters,
                           scoring = 'accuracy',
                           cv = 10,
                           n_jobs = -1)
grid_search = grid_search.fit(X_train, y_train)
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_
